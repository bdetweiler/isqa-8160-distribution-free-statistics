---
title: "ISQA 8160 Exam II"
author: "Brian Detweiler"
date: "Thursday, July 28, 2016"
header-includes:
   - \usepackage{bbm}
   - \usepackage[utf8]{inputenc}
   - \usepackage{amsmath}
   - \usepackage{amssymb}
   - \usepackage{color}
   - \usepackage{progressbar}
   - \usepackage{array}
   - \usepackage{tikz}
   - \usepackage{verbatim}
   - \usepackage{color,soul}
   - \usepackage{blkarray}
   - \usepackage[utf8]{inputenc}
   - \usepackage{amssymb}
   - \usepackage{pifont}
   - \usepackage{diagbox}
   - \usepackage{listings}
   - \usepackage{color}
output: pdf_document
---

$$
% Matrix variable boldface
\newcommand{\matr}[1]{\mathbf{#1}}
% I seem to typo this a lot, so we'll just alias it
\newcommand{\fraC}[2]{\frac{#1}{#2}}
% for repeating values
\newcommand*\repeating[1]{\overline{#1}}
\newcommand{\xmark}{\ding{55}}%
\newcommand\tab[1][1cm]{\hspace*{#1}}
\newcommand\encircle[1]{%
  \tikz[baseline=(X.base)] 
    \node (X) [draw, shape=circle, inner sep=0] {\strut #1};}
\newcommand{\specialcell}[2][c]{%
  \begin{tabular}[#1]{@{}c@{}}#2\end{tabular}}
\newcommand{\ceil}[1]{\left \lceil #1 \right \rceil }
\newcommand{\floor}[1]{\left \lfloor #1 \right \rfloor }
$$


# Chapter 3.1

## 3.1 Problem 6.) A civic group reported to the town council that at least 60\% of the town residents were in favor of a particular bond issue. Forty-eight said yes. Is the report of the civic group reasonable?

We have the following:
$$
\begin{split}
    p &= 0.60\\
    p^{*} &= 0.48\\
    n &= 100\\
    \alpha &= 0.05\\
\end{split}
$$

The null hypothesis is that the sample probability is representative of a population probability of 60%. The alternative hypothesis is that they are not equal.

$$
\begin{split}
    H_0 &: p = p^*\\
    H_a &: p \neq p^*\\
\end{split}
$$

```{r, echo=FALSE}
# Suppress version warnings
options(warn=-1)
```

```{r}
library(binom)
binom.test(x=48, n=100, p=0.60, alternative=c('two.sided'), conf.level=0.95)
```

And thus we reject the null hypothesis with a p-value of 0.01844 and a 95% confidence interval of (0.3790055, 0.5822102). The population mean appears to be less than 60%.

\begin{flushright}
  $\blacksquare$
\end{flushright}

\pagebreak


## 3.1 Problem 7.) Out of 20 recent takeover attempts, 5 were successfully resisted byt the companies being taken over. Assume these are independent events, and estimate the probability of a takeover attempt being successfully resisted. That is, find a 95% confidence interval.

Setting up this problem we have the following values:
$$
\begin{split}
    n &= 20\\
    x &= 5\\
\end{split}
$$

We can find the confidence interval using the binom.test like before:

```{r}
binom.test(x=5, n=20, alternative=c('two.sided'), conf.level=0.95)
```

### (a) Use Table A4.

*Table A4* confirms the 95% confidence interval as (0.087, 0.491).

### (b) Use Table A1.

Although $n = 20$ is a smaller sample size than we generally require for using the normal distribution, we can nevertheless use it to obtain a slightly less accurate answer:

$$
\begin{split}
    L &= \frac{Y}{n} - z_{1-\frac{\alpha}{2}} \sqrt{\frac{Y(n - Y)}{n^3}}\\
    U &= \frac{Y}{n} + z_{1-\frac{\alpha}{2}} \sqrt{\frac{Y(n - Y)}{n^3}}\\
\end{split}
$$

The z-value at $z_{1 - \frac{0.05}{2}} = z_{0.975}$ is 1.96. Plugging in our values, we get

```{r}
L <- (5/20) - 1.96 * sqrt((20 * (20 - 5)) / (20^3))
U <- (5/20) + 1.96 * sqrt((20 * (20 - 5)) / (20^3))
print(paste(paste(paste(paste('(', L),  ', '), U), ')'))
```

Clearly, with such a small sample size, the normal approximation will not return accurate results.

\begin{flushright}
  $\blacksquare$
\end{flushright}

\pagebreak


# Chapter 3.2

## 3.2 Problem 1.) A random sample of tenth-grade boys resulted int he following 20 observed weights.

\begin{center}
\begin{tabular}{ c c c c c}
  142 & 134 & 98  & 119 & 131\\
  103 & 154 & 122 & 93  & 137\\
  86  & 119 & 161 & 144 & 158\\
  165 & 81  & 117 & 128 & 103\\
\end{tabular}
\end{center}

## Test the hypothesis that the median weight is 103.

Let's first order the data.
```{r}
weights <- sort(c(142, 134, 98,  119, 131,
                  103, 154, 122, 93,  137,
                  86,  119, 161, 144, 158, 
                  165, 81,  117, 128, 103))
weights.df <- as.data.frame(weights)
weights.df
```
We will test the hypothesis that $x_{0.50} = 103$ with $\alpha = 0.05$.

$$
\begin{split}
    H_0 &: p = p^*\\
    H_a &: p \neq p^*\\
    x^* &= 103\\
    T_1 &= \text{number of } x_i \leq x^*\\
    T_2 &= \text{number of } x_i < x^*\\
\end{split}
$$

```{r}
T1 <- length(weights.df[weights.df$weights <= 103, ])
T1
T2 <- length(weights.df[weights.df$weights < 103, ])
T2
```

Since $n \leq 20$, the critical region is $c = \{T_1 \leq t_1, T_2 \geq t_2\}$, such that $P(y \leq t_1) = \frac{\alpha}{2}$ and $P(y \leq t_2) = 1 - \frac{\alpha}{2}$.

$$
\begin{split}
    T_1 &= \text{number of } x_i \leq 103 = 6\\
    T_2 &= \text{number of } x_i < 103 = 4\\
    c &= \{6 \leq t_1 \text{ or } 4 > t_2\}\\
    P(y \leq t_1) &= 0.025\\
    P(y \leq t_2) &= 0.975\\
\end{split}
$$

```{r}
trials <- 20
probability <- 0.50
alpha <- 0.05
left.crit.region <- alpha / 2
right.crit.region <- 1 - (alpha / 2)
```

```{r, echo=FALSE}
n <- seq(0, trials, by=1)
barplot(pbinom(n, trials, probability), names.arg=n, xlab=paste(paste(paste('Cumulative Binom(', trials), probability, sep=','), ')'))
```

```{r}

# binomsum(start, end, n, p)
# Gives a cumulative sum of the binomial from start to end, for n trials with p probability
binomsum <- function(start, end, n, p) sum(dbinom(x=c(start:end), size=n, prob=p))

# cumsums is a list of the cumulative probability at each point
cumsums <- list(mapply(binomsum, 0, c(0:trials), trials, probability))

# gives a TRUE/FALSE list where values are <= alpha/2
left.tail <- lapply(cumsums, function(x) x <= left.crit.region)

# gives a TRUE/FALSE list where values are >= 1 - (alpha / 2)
right.tail <- lapply(cumsums, function(x) x >= right.crit.region)

# Table sums up values
left.tail.table <- table(left.tail)
right.tail.table <- table(right.tail)

# Note that zero is counted in here, so we must subtract 1, otherwise we get
# the value that sits outside outside of the range
t1 <- as.data.frame(left.tail.table[names(left.tail.table) == T])[1, 1] - 1
t1

# Zero is counted in here, so we need to add one to get the value we're looking for
# Also, recall we want t2 s.t. P(y <= t2) = 1 - alpha/2, or P(y <= t2) = 0.975
# In other words, this will the the majority of the distribution
t2 <- trials - as.data.frame(right.tail.table[names(right.tail.table) == T])[1, 1] + 1
t2

T1.prob <- pbinom(q=T1, size=trials, prob=probability)
T1.prob

T2.prob <- 1 - pbinom(q=T2, size=trials, prob=probability)
T2.prob
```

Now it is clear,

$$
\begin{split}
    T_1 &= 6\\
    T_2 &= 4\\
    t_1 &= 5\\
    t_2 &= 14\\
    c &= \{6 \nleq 5 \text{ or } 4 \ngtr 14\}\\
\end{split}
$$

So we cannot reject the null hypothesis with a p-value of
```{r}
min(2*T1.prob, 2*T2.prob)
```

\begin{flushright}
  $\blacksquare$
\end{flushright}

\pagebreak


## 2.) In Exercise 1 test the hypothesis that the upper quartile is at least 150.

We will test the hypothesis that $x_{0.75} = 150$ with $\alpha = 0.05$ using a left-tailed test.

$$
\begin{split}
    H_0 &: p \geq p^*\\
    H_a &: p < p^*\\
    c &= \{T_1: T_1 \leq t_1\}
\end{split}
$$

```{r}
T1 <- length(weights.df[weights.df$weights <= 150, ])
T1
```

Since $n \leq 20$, the critical region is $c = \{T_1 \leq t_1\}$, such that $P(y \leq t_1) = \alpha$.

$$
\begin{split}
    T_1 &= \text{number of } x_i \leq 150 = 16\\
    c &= \{16 \leq t_1\}\\
    P(y \leq t_1) &= 0.05\\
\end{split}
$$

```{r}
trials <- 20
probability <- 0.75
alpha <- 0.05
left.crit.region <- alpha
```

```{r, echo=FALSE}
n <- seq(0, trials, by=1)
barplot(pbinom(n, trials, probability), names.arg=n, xlab=paste(paste(paste('Cumulative Binom(', trials), probability, sep=','), ')'))
```

```{r}

# binomsum(start, end, n, p)
# Gives a cumulative sum of the binomial from start to end, for n trials with p probability
binomsum <- function(start, end, n, p) sum(dbinom(x=c(start:end), size=n, prob=p))

# cumsums is a list of the cumulative probability at each point
cumsums <- list(mapply(binomsum, 0, c(0:trials), trials, probability))

# gives a TRUE/FALSE list where values are <= alpha/2
left.tail <- lapply(cumsums, function(x) x <= left.crit.region)

# Table sums up values
left.tail.table <- table(left.tail)

# Note that zero is counted in here, so we must subtract 1, otherwise we get
# the value that sits outside outside of the range
t1 <- as.data.frame(left.tail.table[names(left.tail.table) == T])[1, 1] - 1
t1

T1.prob <- pbinom(q=T1, size=trials, prob=probability)
T1.prob
```

Now it is clear,

$$
\begin{split}
    T_1 &= 16\\
    t_1 &= 11\\
    c &= \{16 \nleq 11\}\\
\end{split}
$$

So we cannot reject the null hypothesis with a p-value of
```{r}
T1.prob
```


\begin{flushright}
  $\blacksquare$
\end{flushright}

\pagebreak


## 3.) In Exercise 1 test the hypothesis that the third decile is no greater than 100.

We will test the hypothesis that $x_{0.30} \leq 100$ with $\alpha = 0.05$ using a right-tailed test.

$$
\begin{split}
    H_0 &: p \leq p^*\\
    H_a &: p > p^*\\
    c &= \{T_2: T_2 \leq t_2\}
\end{split}
$$

```{r}
T2 <- length(weights.df[weights.df$weights < 100, ])
T2
```

Since $n \leq 20$, the critical region is $c = \{T_2 \geq t_2\}$, such that $P(y \geq t_2) = 1 - \alpha$.

$$
\begin{split}
    T_2 &= \text{number of } x_i < 100 = 4\\
    c &= \{4 > t_2\}\\
    P(y \leq t_2) &= 0.95\\
\end{split}
$$

```{r}
trials <- 20
probability <- 0.30
alpha <- 0.05
right.crit.region <- 1 - alpha
```

```{r, echo=FALSE}
n <- seq(0, trials, by=1)
barplot(pbinom(n, trials, probability), names.arg=n, xlab=paste(paste(paste('Cumulative Binom(', trials), probability, sep=','), ')'))
```

```{r}

# binomsum(start, end, n, p)
# Gives a cumulative sum of the binomial from start to end, for n trials with p probability
binomsum <- function(start, end, n, p) sum(dbinom(x=c(start:end), size=n, prob=p))

# cumsums is a list of the cumulative probability at each point
cumsums <- list(mapply(binomsum, 0, c(0:trials), trials, probability))

# gives a TRUE/FALSE list where values are >= 1 - (alpha / 2)
right.tail <- lapply(cumsums, function(x) x >= right.crit.region)

# Table sums up values
right.tail.table <- table(right.tail)

# Zero is counted in here, so we need to add one to get the value we're looking for
# Also, recall we want t2 s.t. P(y <= t2) = 1 - alpha/2, or P(y <= t2) = 0.975
# In other words, this will the the majority of the distribution
t2 <- trials - as.data.frame(right.tail.table[names(right.tail.table) == T])[1, 1] + 1
t2

T2.prob <- 1 - pbinom(q=T2, size=trials, prob=probability)
T2.prob
```

$$
\begin{split}
    T_2 &= 9\\
    t_2 &= 10\\
    c &= \{9 \ngtr 10\}\\
\end{split}
$$

So we cannot reject the null hypothesis with a p-value of
```{r}
T2.prob
```

\begin{flushright}
  $\blacksquare$
\end{flushright}

\pagebreak




## 4.) In Exercise 1 find an approximate 90% confidence interval for the median. What is the exact confidence coefficient? Also compare the results using the exact method with the results obtained using the large sample approximation.


```{r}
trials <- 20
probability <- 0.50
alpha <- 0.10
left.crit.region <- alpha / 2
right.crit.region <- 1 - (alpha / 2)
```

```{r, echo=FALSE}
n <- seq(0, trials, by=1)
barplot(pbinom(n, trials, probability), names.arg=n, xlab=paste(paste(paste('Cumulative Binom(', trials), probability, sep=','), ')'))
```

```{r}

# binomsum(start, end, n, p)
# Gives a cumulative sum of the binomial from start to end, for n trials with p probability
binomsum <- function(start, end, n, p) sum(dbinom(x=c(start:end), size=n, prob=p))

# cumsums is a list of the cumulative probability at each point
cumsums <- list(mapply(binomsum, 0, c(0:trials), trials, probability))

# gives a TRUE/FALSE list where values are <= alpha/2
left.tail <- lapply(cumsums, function(x) x <= left.crit.region)

# gives a TRUE/FALSE list where values are >= 1 - (alpha / 2)
right.tail <- lapply(cumsums, function(x) x >= right.crit.region)

# Table sums up values
left.tail.table <- table(left.tail)
right.tail.table <- table(right.tail)

# Note that zero is counted in here, so we must subtract 1, otherwise we get
# the value that sits outside outside of the range
r <- as.data.frame(left.tail.table[names(left.tail.table) == T])[1, 1] - 1
r

# Zero is counted in here, so we need to add one to get the value we're looking for
# Also, recall we want t2 s.t. P(y <= t2) = 1 - alpha/2, or P(y <= t2) = 0.975
# In other words, this will the the majority of the distribution
s <- trials - as.data.frame(right.tail.table[names(right.tail.table) == T])[1, 1] + 1
s

conf.coef <- pbinom(q=r, size=trials, p=probability) + (1 - pbinom(q=s, size=trials, p=probability))
conf.coef
```

But $r$ and $s$ are the values \textit{below} 0.05 and \text{above} 0.95 respectively. They may not be the closest values. We'll test for these by hand (or we could look them up in the table, by why bother when we have R?)

```{r}
abs(0.05 - pbinom(q=r, size=trials, p=probability))
abs(0.05 - pbinom(q=r+1, size=trials, p=probability))
abs(0.95 - pbinom(q=s, size=trials, p=probability))
abs(0.95 - pbinom(q=s-1, size=trials, p=probability))
```
So we can see that $r + 1 = 6$ and $s - 1 = 13$ are the closes values to a 90% confidence coefficient.

The actual value of the confidence coefficient is
```{r}
conf.coef <- pbinom(q=r+1, size=trials, p=probability) + (1 - pbinom(q=s-1, size=trials, p=probability))
conf.coef
```

This gives us values of
```{r}
weights[r + 1]
weights[s - 1]
```

We can see that $r + 1$ and $s - 1$ are the values of the order statistics, which we found in the \textit{weights} list.

So our approximate 90% confidence interval for $x_{0.50}$ is (103, 134).

Finding the large sample approximation, we get

$$
\begin{split}
    r^* &= np^* + z_{\frac{\alpha}{2}} \sqrt{np^*(1 - p^*)}\\
    &= 20(0.50) + 1.96 \sqrt{20 (.5)(1 - .5)}\\
    &= 10 + 4.38\\
    &= \left \lceil 14.4 \right \rceil\\
    &= 15\\
    \\
    s^* &= np^* + z_{1 - \frac{\alpha}{2}} \sqrt{np^*(1 - p^*)}\\
    &= 20(0.50) - 1.96 \sqrt{20 (.5)(1 - .5)}\\
    &= 20(0.50) - 1.96 \sqrt{20 (.5)(1 - .5)}\\
    &= 10 - 4.38\\
    &= \left \lceil 5.62 \right \rceil \\
    &= 6
\end{split}
$$

```{r}
weights[r]
weights[s]
```

And so our large sample approximation for a 90% confidence interval is (103, 137)
\begin{flushright}
  $\blacksquare$
\end{flushright}

\pagebreak

## 8.) Armor plating with a thickness of 10 cm is being tested to see how deeply a given projectile will penetrate armor. Fifty projectiles are fired at the armor plating, and the depth of penetration is measured. Seven of the projectiles pierced a hole through the armor plating, so their depth of penetration is recorded as 10+. All fifty values, ordered from smallest to largest, are given as follows.

5.37, 5.39, 5.42, 5.51, 5.63, 5.74, 5.82, 5.83, 5.94, 5.98, 6.07, 6.07, 6.13, 6.20, 6.21, 6.23, 6.25, 


